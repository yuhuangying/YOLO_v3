{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# AbsolutePath = os.path.abspath(__file__)           #将相对路径转换成绝对路径\n",
    "# SuperiorCatalogue = os.path.dirname(AbsolutePath)   #相对路径的上级路径\n",
    "# BaseDir = os.path.dirname(SuperiorCatalogue)        #在“SuperiorCatalogue”的基础上在脱掉一层路径，得到我们想要的路径。\n",
    "# sys.path.insert(0,BaseDir)                          #将我们取出来的路径加入\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from model.backbones.darknet53 import Darknet53\n",
    "from model.necks.yolo_fpn import FPN_YOLOV3\n",
    "from model.head.yolo_head import Yolo_head\n",
    "from model.layers.conv_module import Convolutional\n",
    "import config.yolov3_config_voc as cfg\n",
    "import numpy as np\n",
    "from utils.tools import *\n",
    "\n",
    "\n",
    "class Yolov3(nn.Module):\n",
    "    \"\"\"\n",
    "    Note ： int the __init__(), to define the modules should be in order, because of the weight file is order\n",
    "    \"\"\"\n",
    "    def __init__(self, init_weights=True):\n",
    "        super(Yolov3, self).__init__()\n",
    "\n",
    "        self.__anchors = torch.FloatTensor(cfg.MODEL[\"ANCHORS\"])\n",
    "        self.__strides = torch.FloatTensor(cfg.MODEL[\"STRIDES\"])\n",
    "        self.__nC = cfg.DATA[\"NUM\"]\n",
    "        self.__out_channel = cfg.MODEL[\"ANCHORS_PER_SCLAE\"] * (self.__nC + 5)\n",
    "\n",
    "        self.__backnone = Darknet53()\n",
    "        self.__fpn = FPN_YOLOV3(fileters_in=[1024, 512, 256],\n",
    "                                fileters_out=[self.__out_channel, self.__out_channel, self.__out_channel])\n",
    "\n",
    "        # small\n",
    "        self.__head_s = Yolo_head(nC=self.__nC, anchors=self.__anchors[0], stride=self.__strides[0])\n",
    "        # medium\n",
    "        self.__head_m = Yolo_head(nC=self.__nC, anchors=self.__anchors[1], stride=self.__strides[1])\n",
    "        # large\n",
    "        self.__head_l = Yolo_head(nC=self.__nC, anchors=self.__anchors[2], stride=self.__strides[2])\n",
    "\n",
    "        if init_weights:\n",
    "            self.__init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "\n",
    "        x_s, x_m, x_l = self.__backnone(x)\n",
    "        x_s, x_m, x_l = self.__fpn(x_l, x_m, x_s)\n",
    "\n",
    "        out.append(self.__head_s(x_s))\n",
    "        out.append(self.__head_m(x_m))\n",
    "        out.append(self.__head_l(x_l))\n",
    "\n",
    "        if self.training:\n",
    "            p, p_d = list(zip(*out))\n",
    "            return p, p_d  # smalll, medium, large\n",
    "        else:\n",
    "            p, p_d = list(zip(*out))\n",
    "            return p, torch.cat(p_d, 0)\n",
    "\n",
    "\n",
    "    def __init_weights(self):\n",
    "\n",
    "        \" Note ：nn.Conv2d nn.BatchNorm2d'initing modes are uniform \"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                print(\"initing {}\".format(m))\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                torch.nn.init.constant_(m.weight.data, 1.0)\n",
    "                torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "                print(\"initing {}\".format(m))\n",
    "\n",
    "\n",
    "    def load_darknet_weights(self, weight_file, cutoff=52):\n",
    "        \"https://github.com/ultralytics/yolov3/blob/master/models.py\"\n",
    "\n",
    "        print(\"load darknet weights : \", weight_file)\n",
    "\n",
    "        with open(weight_file, 'rb') as f:\n",
    "            _ = np.fromfile(f, dtype=np.int32, count=5)\n",
    "            weights = np.fromfile(f, dtype=np.float32)\n",
    "        count = 0\n",
    "        ptr = 0\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Convolutional):\n",
    "                # only initing backbone conv's weights\n",
    "                if count == cutoff:\n",
    "                    break\n",
    "                count += 1\n",
    "\n",
    "                conv_layer = m._Convolutional__conv\n",
    "                if m.norm == \"bn\":\n",
    "                    # Load BN bias, weights, running mean and running variance\n",
    "                    bn_layer = m._Convolutional__norm\n",
    "                    num_b = bn_layer.bias.numel()  # Number of biases\n",
    "                    # Bias\n",
    "                    bn_b = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(bn_layer.bias.data)\n",
    "                    bn_layer.bias.data.copy_(bn_b)\n",
    "                    ptr += num_b\n",
    "                    # Weight\n",
    "                    bn_w = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(bn_layer.weight.data)\n",
    "                    bn_layer.weight.data.copy_(bn_w)\n",
    "                    ptr += num_b\n",
    "                    # Running Mean\n",
    "                    bn_rm = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(bn_layer.running_mean)\n",
    "                    bn_layer.running_mean.data.copy_(bn_rm)\n",
    "                    ptr += num_b\n",
    "                    # Running Var\n",
    "                    bn_rv = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(bn_layer.running_var)\n",
    "                    bn_layer.running_var.data.copy_(bn_rv)\n",
    "                    ptr += num_b\n",
    "\n",
    "                    print(\"loading weight {}\".format(bn_layer))\n",
    "                else:\n",
    "                    # Load conv. bias\n",
    "                    num_b = conv_layer.bias.numel()\n",
    "                    conv_b = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(conv_layer.bias.data)\n",
    "                    conv_layer.bias.data.copy_(conv_b)\n",
    "                    ptr += num_b\n",
    "                # Load conv. weights\n",
    "                num_w = conv_layer.weight.numel()\n",
    "                conv_w = torch.from_numpy(weights[ptr:ptr + num_w]).view_as(conv_layer.weight.data)\n",
    "                conv_layer.weight.data.copy_(conv_w)\n",
    "                ptr += num_w\n",
    "\n",
    "                print(\"loading weight {}\".format(conv_layer))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net = Yolov3()\n",
    "    print(net)\n",
    "\n",
    "    in_img = torch.randn(12, 3, 416, 416)\n",
    "    p, p_d = net(in_img)\n",
    "\n",
    "    for i in range(3):\n",
    "        print(p[i].shape)\n",
    "        print(p_d[i].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
